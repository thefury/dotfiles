<p>AWS customers can use tags to assign metadata to their AWS resources. Each tag is a simple label consisting of a customer-defined key and an optional value that can make it easier to manage, search for, and filter resources. Although there are no inherent types of tags, they enable customers to categorize resources by <a href="https://aws.amazon.com/answers/account-management/aws-tagging-strategies/">multiple criteria</a> such as purpose, owner and, environment.</p> 
<p>Once a tagging strategy is defined and enforced, customers can use the <a href="https://aws.amazon.com/premiumsupport/knowledge-center/intro-tag-editor/">AWS Tag Editor</a> to view and manage tags on their AWS resources, regardless of service or region. They can use the tag editor to search for resources by resource type, region, or tag, and then manage the tags applied to those resources.</p> 
<p>However, customers have asked for guidance on how to build custom automation mechanisms to extract and query tagged resources so that they can extend the built-in functionalities of the Tag Editor. For instance, customers can build automation to generate custom CSV files for tagged resources and perhaps use SQL to query those resources. In addition, automation allows customers to add validation checks to their CI/CD deployment pipelines, for instance, to check whether resources have been properly tagged.</p> 
<p>In this blog post, we introduce a simple yet efficient AWS architecture for extracting and querying tagged resources based on AWS cloud-native features such as the <a href="https://aws.amazon.com/blogs/aws/new-aws-resource-tagging-api/">Resource Tagging API</a> and <a href="https://aws.amazon.com/blogs/aws/s3-glacier-select/">S3 Select</a>. We provide sample code for the architecture discussed that can help customers to customize and/or extend the architecture for their own purpose. By relying on AWS cloud-native features, customers can save time and reduce costs while still being able to do customizations.</p> 
<p>For customers unfamiliar with the Resource Tagging API and the S3 Select features, below is a very brief introduction.</p> 
<p><strong>Resource Tagging API</strong><br /> AWS customers can use the Resource Tagging API to programatically access the same resource group operations that had been accessible only from the AWS Management Console by now using the AWS SDKs or the AWS Command Line Interface (CLI). By doing so, customers can build automation that fits their need, e.g., code that extract, export, and queries tagged resources.</p> 
<p>For further details, please read <a href="https://docs.aws.amazon.com/resourcegroupstagging/latest/APIReference/Welcome.html">Resource Groups Tagging – Reference</a></p> 
<p><strong>S3 Select</strong><br /> S3 Select enables applications to retrieve only a subset of data from an object by using simple SQL expressions. By using S3 Select to retrieve only the data needed by the application, customers can achieve drastic performance increases – in many cases you can get as much as a 400% improvement.</p> 
<p>For further details, please read:</p> 
<ul> 
 <li><a href="https://aws.amazon.com/blogs/aws/s3-glacier-select/">S3 Select and Glacier Select – Retrieving Subsets of Objects</a></li> 
 <li><a href="https://aws.amazon.com/blogs/aws/amazon-s3-update-new-storage-class-general-availability-of-s3-select/">Amazon S3 Update: New Storage Class and General Availability of S3 Select</a></li> 
</ul> 
<p><strong>The Overall Solution Architecture</strong><br /> <img class="aligncenter wp-image-820 size-large" src="https://d2908q01vomqb2.cloudfront.net/fc074d501302eb2b93e2554793fcaf50b3bf7291/2018/08/22/taggings3arch-1024x581.png" alt="" width="1024" height="581" /></p> 
<p>The figure above depict the overall architecture discussed in this post. It is a simple yet efficient architecture for extracting and querying tagged resources based on AWS cloud-native features. The Resource Tagging API is used to extract tagged resources from one or more AWS accounts via the <a href="https://aws.amazon.com/sdk-for-python/">Python AWS SDK</a>, then a custom CSV file is generated and pushed to S3. Once in S3, the tagged resources file can now be efficiently queried via S3 Select also using Python AWS SDK. By leveraging S3 Select, we can now use SQL to query tagged resources and save on S3 data transfer costs since only the filtered results will be returned directly from S3. Pretty neat, eh?</p> 
<p><strong>The Extract Process</strong><br /> The extract process was built using Python 3 and relies on the Resource Tagging API to fetch pages of tagged resources and export them to CSV using the csv Python library.</p> 
<p>We start importing the required libraries (boto3 is the AWS SDK for Python, argparse helps managing input parameters, and csv supports building valid CSV files):</p> 
<div class="hide-language"> 
 <pre><code class="lang-python">import boto3
import argparse
import csv
</code></pre> 
</div> 
<p>Then, we define the header columns to use when generating the CSV files containing all tagged resources and the writeToCsv function:</p> 
<div class="hide-language"> 
 <pre><code class="lang-python">field_names = ['ResourceArn', 'TagKey', 'TagValue']

def writeToCsv(writer, args, tag_list):
    for resource in tag_list:
        print(&quot;Extracting tags for resource: &quot; +
              resource['ResourceARN'] + &quot;...&quot;)
        for tag in resource['Tags']:
            row = dict(
                ResourceArn=resource['ResourceARN'], TagKey=tag['Key'], TagValue=tag['Value'])
            writer.writerow(row)
</code></pre> 
</div> 
<p>We take the CSV output file path as a required parameter so that users can specificy the desired output file name using the argparse library:</p> 
<div class="hide-language"> 
 <pre><code class="lang-python">def input_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(&quot;--output&quot;, required=True,
                        help=&quot;Output CSV file (eg, /tmp/tagged-resources.csv)&quot;)
    return parser.parse_args()</code></pre> 
</div> 
<p>And then, we implement the main extract logic that uses the Resource Tagging API (see boto3.client(‘resourcegroupstaggingapi’) in the code below). Note that we fetch 50 resources at a time and write them to the CSV output file until no more resources are found.</p> 
<div class="hide-language"> 
 <pre><code class="lang-python">def main():
    args = input_args()
    restag = boto3.client('resourcegroupstaggingapi')
    with open(args.output, 'w') as csvfile:
        writer = csv.DictWriter(csvfile, quoting=csv.QUOTE_ALL,
                                delimiter=',', dialect='excel', fieldnames=field_names)
        writer.writeheader()
        response = restag.get_resources(ResourcesPerPage=50)
        writeToCsv(writer, args, response['ResourceTagMappingList'])
        while 'PaginationToken' in response and response['PaginationToken']:
            token = response['PaginationToken']
            response = restag.get_resources(
                ResourcesPerPage=50, PaginationToken=token)
            writeToCsv(writer, args, response['ResourceTagMappingList'])

if __name__ == '__main__':
    main()</code></pre> 
</div> 
<p>The extract procedure is pretty simple and illustrates well how to use the Resource Tagging API to customize the output. It will also use the default credentials in your account.</p> 
<p>Here is how the extract process can be triggered for the QA account (assuming the python source file is named&nbsp;<code class="lang-python">aws-tagged-resources-extractor.py</code> and that there is a <code class="lang-python">QA_AWS_ACCOUNT AWS</code> profile defined in your&nbsp;<code class="lang-python">~/.aws/credentials</code> file).</p> 
<div class="hide-language"> 
 <pre><code class="lang-python">export AWS_PROFILE=QA_AWS_ACCOUNT
python aws-tagged-resources-extractor.py --output /tmp/qa-tagged-resources.csv
</code></pre> 
</div> 
<p>The extract procedure can be applied to other AWS accounts by updating the&nbsp;<code class="lang-python">AWS_PROFILE</code>&nbsp;environment variable accordingly.</p> 
<p>The extract procedure can be applied to other AWS accounts by updating the&nbsp;<code class="lang-python">AWS_PROFILE</code> environment variable accordingly.</p> 
<p><strong>The ‘Upload to S3’ Process</strong><br /> Once file /tmp/qa-tagged-resources.csv is generated, it can be upload to an S3 bucket using the <a href="https://aws.amazon.com/cli/">AWS CLI</a> (or one could extend the extract sample code above to do so):</p> 
<div class="hide-language"> 
 <pre><code class="lang-python">aws s3 cp /tmp/qa-tagged-resources.csv s3://[REPLACE-WITH-YOUR-S3-BUCKET]</code></pre> 
</div> 
<p><strong>The Query Process</strong><br /> Once the CSV files containing tagged resources for different AWS accounts are uploaded to S3, we can now use S3 Select to perform familiar SQL queries against these files. Another advantage of using S3 Select is that it reduces the amount of data transferred from S3 which is especially relevant in our case when accounts have a very large number of tagged resources.</p> 
<p>We again use the boto3 and argparse libraries (Python 3). Required input parameters include the S3 bucket (–bucket) and the S3 key (–key). The SQL query parameter (–query) is optional and will return all results if not provided.</p> 
<div class="hide-language"> 
 <pre><code class="lang-python">import boto3
import argparse

def input_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(&quot;--bucket&quot;, required=True, help=&quot;SQL query to filter tagged resources output&quot;)
    parser.add_argument(&quot;--key&quot;, required=True, help=&quot;SQL query to filter tagged resources output&quot;)
    parser.add_argument(&quot;--query&quot;, default=&quot;select * from s3object&quot;, help=&quot;SQL query to filter tagged resources output&quot;)
    return parser.parse_args()</code></pre> 
</div> 
<p>The main query logic is shown below. It uses the boto3.client(‘s3’) to initialize an s3 client that is later used to query the tagged resources CSV file in S3 via the select_object_content() function. This function takes the S3 bucket name, S3 key, and query as parameters. Check the [Boto3] (http://boto3.readthedocs.io/en/latest/reference/services/s3.html) API reference for details on this function and its inputs and outputs.</p> 
<div class="hide-language"> 
 <pre><code class="lang-python">def main():
    args = input_args()
    s3 = boto3.client('s3')
    response = s3.select_object_content(
        Bucket=args.bucket,
        Key=args.key,
        ExpressionType='SQL',
        Expression=args.query,
        InputSerialization = {'CSV': {&quot;FileHeaderInfo&quot;: &quot;Use&quot;}},
        OutputSerialization = {'CSV': {}},
    )

    for event in response['Payload']:
        if 'Records' in event:
            records = event['Records']['Payload'].decode('utf-8')
            print(records)
            
if __name__ == '__main__':
    main()
</code></pre> 
</div> 
<p>Here’s a few examples of how to trigger the query procedure against the CSV files stored in S3 (assuming the Python source file for the query procedure is called aws-tagged-resources-querier). We assume that the S3 bucket is located in a single account referenced by profile <code class="lang-python">CENTRAL_AWS_ACCOUNT</code>.</p> 
<p><strong>Return the resource ARNs of all route tables containing a tag named ‘aws:cloudformation:stack-name’ in the QA AWS account</strong></p> 
<div class="hide-language"> 
 <pre><code class="lang-python">export AWS_PROFILE= CENTRAL_AWS_ACCOUNT
python aws-tagged-resources-querier \
&nbsp;&nbsp;&nbsp;&nbsp; --bucket [REPLACE-WITH-YOUR-S3-BUCKET] \
&nbsp;&nbsp;&nbsp;&nbsp; --key qa-tagged-resources.csv \
&nbsp;&nbsp;&nbsp;&nbsp; --query &quot;select ResourceArn from s3object s \
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; where s.ResourceArn like 'arn:aws:ec2%route-table%' \
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; and s.TagKey='aws:cloudformation:stack-name'&quot;</code></pre> 
</div> 
<p>We invite readers to build more sophisticated SQL queries.</p> 
<p><strong>Summary</strong><br /> In this blog post, we introduced a simple yet efficient AWS architecture for extracting and querying tagged resources based on AWS cloud-native features such as the Resource Tagging API and S3 Select. We provided sample code that can help customers to customize and/or extend the architecture for their own purpose. By relying on AWS cloud-native features, customers can save time and reduce costs while still being able to do customizations.</p> 
<p>The “extract” process discussed above is available in the <a href="https://aws.amazon.com/serverless/serverlessrepo/">AWS Serverless Repository</a> under an application called <a href="https://serverlessrepo.aws.amazon.com/applications/arn:aws:serverlessrepo:us-east-1:423596961626:applications~aws-tag-explorer">aws-tag-explorer</a>. Check it out!</p> 
<p>Happy Resource Tagging!</p> 
<p><strong>About the Author</strong></p> 
<p><img class="wp-image-827 size-thumbnail alignleft" src="https://d2908q01vomqb2.cloudfront.net/fc074d501302eb2b93e2554793fcaf50b3bf7291/2018/08/22/marcilio-116x150.jpg" alt="" width="116" height="150" />Marcilio Mendonca is a Sr.&nbsp;Consultant in the Global DevOps Team at AWS Professional Services. In the past years, he has been helping AWS customers to design, build and deploy best-in-class cloud-native AWS applications using VMs, containers and serverless architectures. Prior to joining AWS, Marcilio was a Software Development Engineer with Amazon. Marcilio also holds a PhD in Computer Science.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p>