<p>In the world of big data, a common use case is performing extract, transform (ET) and data analytics on huge amounts of data from a variety of data sources. Often, you then analyze the data to get insights. One of the most popular cloud-based solutions to process such vast amounts of data is <a href="https://aws.amazon.com/emr/" target="_blank" rel="noopener">Amazon EMR</a>.</p> 
<p>Amazon EMR is a managed cluster platform that simplifies running big data frameworks, such as&nbsp;<a href="https://aws.amazon.com/elasticmapreduce/details/hadoop" target="_blank" rel="noopener">Apache Hadoop</a> and <a href="https://aws.amazon.com/elasticmapreduce/details/spark" target="_blank" rel="noopener">Apache Spark</a>, on AWS. Amazon EMR enables organizations to spin up a cluster with multiple instances in a matter of few minutes. It also enables you to process various data engineering and&nbsp;business intelligence workloads through parallel processing. By doing this, to a great extent you can reduce the data processing times, effort, and costs involved in establishing and scaling a cluster.</p> 
<p>Apache Spark is a cluster-computing software framework that is open-source, fast, and general-purpose. It is widely used in distributed processing of big data. Apache Spark relies heavily on cluster memory (RAM) as it performs parallel computing&nbsp;in memory across nodes&nbsp;to&nbsp;reduce the I/O and execution times of tasks.</p> 
<p>Generally, you perform the following steps when running a Spark application on Amazon EMR:</p> 
<ol> 
 <li>Upload the Spark application package to <a href="https://aws.amazon.com/s3/" target="_blank" rel="noopener">Amazon S3</a>.</li> 
 <li>Configure and launch the Amazon EMR cluster with configured Apache Spark.</li> 
 <li>Install the application package from Amazon S3 onto the cluster and then run the application.</li> 
 <li>Terminate the cluster after the application is completed.</li> 
</ol> 
<p>It’s important to configure the Spark application appropriately based on data and processing requirements for it to be successful. With default settings, Spark might not use all the available resources of the cluster and might end up with physical or virtual memory issues, or both. There are thousands of <a href="https://www.google.com/search?q=emr+spark+memory+issues+site:stackoverflow.com&amp;client=firefox-b-ab&amp;biw=3129&amp;bih=1304&amp;ei=EMTQW9yzBc-Ak-4P78K5wAw&amp;start=10&amp;sa=N" target="_blank" rel="noopener">questions</a>&nbsp;raised in <a href="http://stackoverflow.com" target="_blank" rel="noopener">stackoverflow.com</a>&nbsp;related to this specific topic.</p> 
<p>This blog post is intended to assist you by detailing best practices to prevent memory-related issues with Apache Spark on Amazon EMR.</p> 
<h2>Common memory issues in Spark applications with default or improper configurations</h2> 
<p>Listed following are a few sample out-of-memory errors that can occur in a Spark application with default or improper configurations.</p> 
<p><strong>Out of Memory Error, Java Heap Space</strong></p> 
<div class="hide-language"> 
 <pre><code class="lang-code">WARN TaskSetManager: Loss was due to 
java.lang.OutOfMemoryError
java.lang.OutOfMemoryError: Java heap space</code></pre> 
</div> 
<p><strong>Out of Memory Error, Exceeding Physical Memory</strong></p> 
<div class="hide-language"> 
 <pre><code class="lang-code">Error: ExecutorLostFailure Reason: Container killed by YARN for exceeding limits.
12.4 GB of 12.3 GB physical memory used. 
Consider boosting spark.yarn.executor.memoryOverhead.
Error: ExecutorLostFailure Reason: Container killed by YARN for exceeding limits.
4.5GB of 3GB physical memory used limits.
Consider boosting spark.yarn.executor.memoryOverhead.</code></pre> 
</div> 
<p><strong>Out of Memory Error, Exceeding Virtual Memory</strong></p> 
<div class="hide-language"> 
 <pre><code class="lang-code">Container killed by YARN for exceeding memory limits.
1.1gb of 1.0gb virtual memory used. Killing container.</code></pre> 
</div> 
<p><strong>Out of Memory Error, Exceeding Executor Memory</strong></p> 
<div class="hide-language"> 
 <pre><code class="lang-code">Required executor memory (1024+384 MB) is above 
the max threshold (896 MB) of this cluster! Please check the values of 'yarn.scheduler.maximum-allocation-mb'
and/or 'yarn.nodemanager.resource.memory-mb</code></pre> 
</div> 
<p>These issues occur for various reasons, some of which are listed following:</p> 
<ol> 
 <li>When the number of Spark executor instances, the amount of executor memory, the number of cores, or parallelism is not set appropriately to handle large volumes of data.</li> 
 <li>When the Spark executor’s physical memory exceeds the memory allocated by YARN. In this case, the total of Spark executor instance memory plus memory overhead is not enough to handle memory-intensive operations. Memory-intensive operations include caching, shuffling, and aggregating (using <code>reduceByKey</code>, <code>groupBy</code>, and so on). Or, in some cases, the total of Spark executor instance memory plus memory overhead can be more than what is defined in <code>yarn.scheduler.maximum-allocation-mb</code>.</li> 
 <li>The memory required to perform system operations such as garbage collection is not available in the Spark executor instance.</li> 
</ol> 
<p>In the following sections, I discuss how to properly configure to prevent out-of-memory issues, including but not limited to those preceding.</p> 
<h2>Configuring for a successful Spark application on Amazon EMR</h2> 
<p>The following steps can help you configure a successful Spark application on Amazon EMR.</p> 
<h3>1. Determine the type and number of instances based on application needs</h3> 
<p>Amazon EMR has three types of nodes:</p> 
<ol> 
 <li>Master: An EMR cluster has one master, which acts as the resource manager and manages the cluster and tasks.</li> 
 <li>Core: The core nodes are managed by the master node. Core nodes run YARN NodeManager daemons, Hadoop MapReduce tasks, and Spark executors to manage storage, execute tasks, and send a heartbeat to the master.</li> 
 <li>Task: The optional task-only nodes perform tasks and don’t store any data, in contrast to core nodes.</li> 
</ol> 
<blockquote>
 <p><strong>Best practice 1:&nbsp;</strong>Choose the right type of instance for each of the node types in an Amazon EMR cluster. Doing this is one key to success in running any Spark application on Amazon EMR.</p>
</blockquote> 
<p>There are numerous instance types&nbsp;<a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-supported-instance-types.html" target="_blank" rel="noopener">offered by AWS&nbsp;</a>with varying ranges of vCPUs, storage, and memory, as described in the Amazon EMR documentation. Based on whether an application is compute-intensive or memory-intensive, you can choose the right instance type with the right compute and memory configuration.</p> 
<p>For memory-intensive applications, prefer R type instances over the other instance types. For compute-intensive applications, prefer C type instances.&nbsp;For applications balanced between memory and compute, prefer M type general-purpose instances.</p> 
<p>To understand the possible use cases for each instance type offered by AWS, see&nbsp;<a href="https://aws.amazon.com/ec2/instance-types/" target="_blank" rel="noopener">Amazon EC2 Instance Types</a> on the EC2 service website.</p> 
<p>After deciding the instance type, determine the number of instances for each of the node types. You do this based on the size of the input datasets, application execution times, and frequency requirements.</p> 
<h3>2. Determine the Spark configuration parameters</h3> 
<p>Before we dive into the details on Spark configuration, let’s get an overview of how the executor container memory is organized using the diagram following.</p> 
<p><img class="alignnone size-full wp-image-6682" style="margin: 20px 0px 20px 0px;border: 1px solid #cccccc" src="https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2019/04/02/SparAppsonEMR1.png" alt="" width="800" height="286" /></p> 
<p>As the preceding diagram shows, the executor container has multiple memory compartments. Of these, only one (execution memory) is actually used for executing the tasks. These compartments should be properly configured for running the tasks efficiently and without failure.</p> 
<p>Calculate and set the following Spark configuration parameters carefully for the Spark application to run successfully:</p> 
<ul> 
 <li><code>spark.executor.memory</code> – Size of memory to use for each executor that runs the task.</li> 
 <li><code>spark.executor.cores</code> – Number of virtual cores.</li> 
 <li><code>spark.driver.memory</code> –&nbsp;Size of memory to use for the driver.</li> 
 <li><code>spark.driver.cores</code> – Number of virtual cores to use for the driver.</li> 
 <li><code>spark.executor.instances</code> &shy;– Number of executors. Set this parameter unless <code>spark.dynamicAllocation.enabled</code> is set to true.</li> 
 <li><code>spark.default.parallelism</code> – Default number of partitions in resilient distributed datasets (RDDs) returned by transformations like <code>join</code>, <code>reduceByKey</code>, and <code>parallelize</code> when no partition number is set by the user.</li> 
</ul> 
<p>Amazon EMR provides high-level information on how it sets the default values for Spark parameters <a href="https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-configure.html#spark-defaults" target="_blank" rel="noopener">in the release guide</a>. These values are automatically set in the&nbsp;spark-defaults settings based on the core and task instance types in the cluster.</p> 
<p>To use all the resources available in a cluster, set the <code>maximizeResourceAllocation</code>&nbsp;parameter&nbsp;to true. This EMR-specific option calculates the maximum compute and memory resources available for an executor on an instance in the core instance group. It then sets these parameters in the&nbsp;<code>spark-defaults</code>&nbsp;settings. Even with this setting, generally the default numbers are low and the application doesn’t use the full&nbsp;strength of the cluster. For example, the default for <code>spark.default.parallelism</code>&nbsp;is only 2 x the number of virtual cores available, though parallelism can be higher for a large cluster.</p> 
<p>Spark on YARN can dynamically scale the number of executors used for a Spark application based on the workloads. Using Amazon EMR release version 4.4.0 and later,&nbsp;<a href="https://spark.apache.org/docs/1.6.1/job-scheduling.html#dynamic-resource-allocation" target="_blank" rel="noopener">dynamic allocation</a>&nbsp;is enabled by default (as described in the Spark documentation).</p> 
<p>The problem with the <code>spark.dynamicAllocation.enabled</code>&nbsp;property&nbsp;is that it requires you to set subproperties. Some example subproperties are <code>spark.dynamicAllocation.initialExecutors</code>, <code>minExecutors</code>, and <code>maxExecutors</code>. Subproperties are required for most cases&nbsp;to use the right number of executors in a cluster for an application, especially when you need multiple applications to run simultaneously. Setting subproperties requires a lot of trial and error to get the numbers right. If they’re not right, the capacity might be reserved but never actually used. This leads to wastage of resources or memory errors for other applications.</p> 
<blockquote>
 <p><strong>Best practice 2:&nbsp;</strong>Set <code>spark.dynamicAllocation.enabled</code>&nbsp;to true only if the numbers are properly determined for <code>spark.dynamicAllocation.initialExecutors/minExecutors/maxExecutors</code> parameters. Otherwise, set <code>spark.dynamicAllocation.enabled</code> to false and control the driver memory, executor memory, and CPU parameters yourself. To do this, calculate and set these properties manually for each application (see the example following).</p>
</blockquote> 
<p>Let’s assume that we are going to process 200 terabytes of data spread across thousands of file stores in Amazon S3. Further, let’s assume that we do this through an Amazon EMR cluster with 1&nbsp;r5.12xlarge master node and 19&nbsp;r5.12xlarge core nodes. Each&nbsp;r5.12xlarge instance has 48 virtual cores (vCPUs) and 384 GB RAM. All these calculations are for the&nbsp;<code>--deploy-mode</code>&nbsp;cluster, which we recommend for production use.</p> 
<p>The following list describes how to set some important Spark properties, using the preceding case as an example.</p> 
<p><code>spark.executor.cores</code></p> 
<p style="padding-left: 30px">Assigning executors with a large number of virtual cores leads to a low number of executors and reduced parallelism. Assigning a low number of virtual cores leads to a high number of executors, causing a larger amount of I/O operations. Based on historical data, we suggest that you have five virtual cores for each executor to achieve optimal results in any sized cluster.</p> 
<p style="padding-left: 30px">For the preceding cluster, the property&nbsp;<code>spark.executor.cores</code>&nbsp;should be assigned as follows: <code>spark.executors.cores = 5 (vCPU)</code></p> 
<p><code>spark.executor.memory</code></p> 
<p style="padding-left: 30px">After you decide on the number of virtual cores per executor, calculating this property is much simpler. First, get the number of executors per instance using total number of virtual cores and executor virtual cores. Subtract one virtual core from the total number of virtual cores to reserve it for the Hadoop daemons.</p> 
<pre style="padding-left: 30px"><code class="lang-code">Number of executors per instance = (total number of virtual cores per instance - 1)/ spark.executors.cores

Number of executors per instance = (48 - 1)/ 5 = 47 / 5 = 9 (rounded down)</code></pre> 
<p style="padding-left: 30px">Then, get the total executor memory by using the total RAM per instance and number of executors per instance. Leave 1 GB for the Hadoop daemons.</p> 
<div class="hide-language" style="padding-left: 30px"> 
 <pre><code class="lang-code">Total executor memory = total RAM per instance / number of executors per instance
Total executor memory = 383 / 9 = 42 (rounded down)</code></pre> 
</div> 
<p style="padding-left: 30px">This total executor memory includes the executor memory and overhead (<code>spark.yarn.executor.memoryOverhead</code>). Assign 10 percent from this total executor memory to the memory overhead and the remaining 90 percent to executor memory.</p> 
<div class="hide-language" style="padding-left: 30px"> 
 <pre><code class="lang-code">spark.executors.memory = total executor memory * 0.90
spark.executors.memory = 42 * 0.9 = 37 (rounded down)

spark.yarn.executor.memoryOverhead = total executor memory * 0.10
spark.yarn.executor.memoryOverhead = 42 * 0.1 = 5 (rounded up)</code></pre> 
</div> 
<p><code>spark.driver.memory</code></p> 
<p style="padding-left: 30px">We recommend setting this to equal <code>spark.executors.memory</code>.</p> 
<div class="hide-language" style="padding-left: 30px"> 
 <pre><code class="lang-code">spark.driver.memory = spark.executors.memory</code></pre> 
</div> 
<p><code>spark.driver.cores</code></p> 
<p style="padding-left: 30px">We recommend setting this to equal&nbsp;<code>spark.executors.cores.</code></p> 
<div class="hide-language" style="padding-left: 30px"> 
 <pre><code class="lang-code">spark.driver.cores=&nbsp;spark.executors.cores.</code></pre> 
</div> 
<p><code>spark.executor.instances</code></p> 
<p style="padding-left: 30px">Calculate this by multiplying the number of executors and total number of instances. Leave one executor for the driver.</p> 
<div class="hide-language" style="padding-left: 30px"> 
 <pre><code class="lang-code">spark.executor.instances = (number of executors per instance * number of core instances) minus 1 for the driver

spark.executor.instances = (9 * 19) - 1 = 170</code></pre> 
</div> 
<p><code>spark.default.parallelism</code></p> 
<p style="padding-left: 30px">Set this property using the following formula.</p> 
<div class="hide-language" style="padding-left: 30px"> 
 <pre><code class="lang-code">spark.default.parallelism =&nbsp;spark.executor.instances *&nbsp;spark.executors.cores * 2

spark.default.parallelism = 170 * 5 * 2 = 1,700</code></pre> 
</div> 
<p style="padding-left: 30px"><strong><span style="color: #ff0000">Warning</span>:</strong> Although this calculation gives partitions of 1,700, we recommend that you estimate the size of each partition and adjust this number accordingly by using <code>coalesce</code> or <code>repartition</code>.</p> 
<p style="padding-left: 30px">In case of dataframes, configure the parameter <code>spark.sql.shuffle.partitions</code> along with <code>spark.default.parallelism</code>.</p> 
<p>Though the preceding parameters are critical for any Spark application, the following parameters also help in running the applications smoothly to avoid other timeout and memory-related errors. We advise that you set these in the <code>spark-defaults</code>&nbsp;configuration file.</p> 
<ul> 
 <li><code>spark.network.timeout</code> – Timeout for all network transactions.</li> 
 <li><code>spark.executor.heartbeatInterval</code> – Interval between each executor’s heartbeats to the driver. This&nbsp;value should be significantly less than <code>spark.network.timeout</code>.</li> 
 <li><code>spark.memory.fraction</code> – Fraction of JVM heap space used for Spark execution and storage. The lower this is, the more frequently spills and cached data eviction occur.</li> 
 <li><code>spark.memory.storageFraction</code> – Expressed as a fraction of the size of the region set aside by&nbsp;spark.memory.fraction. The higher this is, the less working memory might be available to execution. This means that tasks might spill to disk more often.</li> 
 <li><code>spark.yarn.scheduler.reporterThread.maxFailures</code> – Maximum number executor failures allowed before YARN can fail the application.</li> 
 <li><code>spark.rdd.compress</code> – When set to true, this property can save substantial space at the cost of some extra CPU time by compressing the RDDs.</li> 
 <li><code>spark.shuffle.compress</code> – When set to true, this property compresses the map output to save space.</li> 
 <li><code>spark.shuffle.spill.compress</code> – When set to true, this property compresses the data spilled during shuffles.</li> 
 <li><code>spark.sql.shuffle.partitions</code> – Sets the number of partitions for joins and aggregations.</li> 
 <li><code>spark.serializer</code> – Sets the serializer to serialize or deserialize data. As a serializer, I prefer Kyro (<code>org.apache.spark.serializer.KryoSerializer</code>), which is faster and more compact than the Java default serializer.</li> 
</ul> 
<p>To understand more about each of the parameters mentioned preceding, see the <a href="https://spark.apache.org/docs/latest/configuration.html#application-properties" target="_blank" rel="noopener">Spark documentation</a>.</p> 
<p>We recommend you consider these additional programming techniques for efficient Spark processing:</p> 
<ul> 
 <li><code>coalesce</code> – Reduces the number of partitions to allow for less data movement.</li> 
 <li><code>repartition</code> – Reduces or increases the number of partitions and performs full shuffle of data as opposed to <code>coalesce</code>.</li> 
 <li><code>partitionBy</code> – Distributes data horizontally across partitions.</li> 
 <li><code>bucketBy</code> – Decomposes data into more manageable parts (buckets) based on hashed columns.</li> 
 <li><code>cache/persist</code> – Pulls datasets into a clusterwide in-memory cache. Doing this is useful when data is accessed repeatedly, such as when querying a small lookup dataset or when running an iterative algorithm.</li> 
</ul> 
<blockquote>
 <p><strong>Best practice 3: </strong>Carefully calculate the preceding additional properties based on application requirements. Set these properties appropriately in <code>spark-defaults</code>, when submitting a Spark application (<code>spark-submit</code>), or within a <code>SparkConf</code> object.</p>
</blockquote> 
<h3>3. Implement a proper garbage collector to clear memory effectively</h3> 
<p>Garbage collection can lead to out-of-memory errors in certain cases. These include cases when there are multiple large RDDs in the application. Other cases occur when there is an interference between the task execution memory and RDD cached memory.</p> 
<p>You can use multiple garbage collectors to evict the old objects and place the new ones into the memory. However, the latest Garbage First Garbage Collector (G1GC) overcomes the latency and throughput limitations with the old garbage collectors.</p> 
<blockquote>
 <p><strong>Best practice 4: </strong>Always set up a garbage collector when handling large volume of data through Spark.</p>
</blockquote> 
<p>The parameter&nbsp;<code>-XX:+UseG1GC</code> specifies that the G1GC garbage collector should be used. (The default is&nbsp;<code>-XX:+UseParallelGC</code>.) To understand the frequency and execution time of the garbage collection, use the parameters <code>-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps</code>. To initiate garbage collection sooner, set <code>InitiatingHeapOccupancyPercent</code> to 35 (the default is 0.45). Doing this helps avoid potential garbage collection for the total memory, which can take a significant amount of time.&nbsp;An example follows.</p> 
<div class="hide-language"> 
 <pre><code class="lang-python">&quot;spark.executor.extraJavaOptions&quot;: &quot;-XX:+UseG1GC -XX:+UnlockDiagnosticVMOptions -XX:+G1SummarizeConcMark -XX:InitiatingHeapOccupancyPercent=35 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:OnOutOfMemoryError='kill -9 %p'&quot;,
&quot;spark.driver.extraJavaOptions&quot;: &quot;-XX:+UseG1GC -XX:+UnlockDiagnosticVMOptions -XX:+G1SummarizeConcMark -XX:InitiatingHeapOccupancyPercent=35 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:OnOutOfMemoryError='kill -9 %p'&quot;,</code></pre> 
</div> 
<h3>4. Set the YARN configuration parameters</h3> 
<p>Even if all the Spark configuration properties are calculated and set correctly, virtual out-of-memory errors can still occur rarely as virtual memory is bumped up aggressively by the OS. To prevent these application failures, set the following flags in the YARN site settings.</p> 
<p><strong>Best practice 5:&nbsp;</strong>Always set the virtual and physical memory check flag to false.</p> 
<div class="hide-language"> 
 <pre><code class="lang-python">&quot;yarn.nodemanager.vmem-check-enabled&quot;:&quot;false&quot;,
&quot;yarn.nodemanager.pmem-check-enabled&quot;:&quot;false&quot;</code></pre> 
</div> 
<h3>5. Perform debugging and monitoring</h3> 
<p>To get details on where the spark configuration options are coming from, you can run&nbsp;spark-submit with the&nbsp;–verbose&nbsp;option. Also, you can use Ganglia and Spark UI to monitor the application progress, Cluster RAM usage, Network I/O, etc.</p> 
<p>In the following example, we compare the outcomes between configured and non-configured Spark applications using Ganglia graphs.</p> 
<p>When configured following the methods described, a Spark application can process 10 TB data successfully without any memory issues on an Amazon EMR cluster whose specs are as follows:</p> 
<ul> 
 <li>1 r5.12xlarge master node</li> 
 <li>19 r5.12xlarge core nodes</li> 
 <li>8 TB total RAM</li> 
 <li>960 total virtual CPUs</li> 
 <li>170 executor instances</li> 
 <li>5 virtual CPUs/executor</li> 
 <li>37 GB memory/executor</li> 
 <li>Parallelism equals 1,700</li> 
</ul> 
<p>Following, you can find Ganglia graphs for reference.</p> 
<p><img class="alignnone size-full wp-image-6680" src="https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2019/04/02/SparAppsonEMR2.png" alt="" width="400" height="237" /><img class="alignnone size-full wp-image-6681" src="https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2019/04/02/SparAppsonEMR3.png" alt="" width="400" height="241" /></p> 
<p>If you run the same Spark application with default configurations on the same cluster, it fails with an out-of-physical-memory error. This is because the default configurations (two executor instances, parallelism of 2, one vCPU/executor, 8-GB memory/executor) aren’t enough to process 10 TB data. Though the cluster had 7.8 TB memory, the default configurations limited the application to use only 16 GB memory, leading to the following out-of-memory error.</p> 
<div class="hide-language"> 
 <pre><code class="lang-code">Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 8, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 10.5 GB of 8 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.</code></pre> 
</div> 
<p>Also, for large datasets, the default garbage collectors don’t clear the memory efficiently enough for the tasks to run in parallel, causing frequent failures. The following charts help in comparing the RAM usage and garbage collection with the default and G1GC garbage collectors.With G1GC, the RAM used is maintained below 5 TB (see the blue area in the graph).</p> 
<p><img class="alignnone size-full wp-image-6679" style="margin: 20px 0px 20px 0px;border: 1px solid #cccccc" src="https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2019/04/02/SparAppsonEMR4.png" alt="" width="752" height="448" /></p> 
<p>With the default garbage collector (CMS), the RAM used goes above 5 TB. This can lead to the failure of the Spark job when running many tasks continuously.</p> 
<p><img class="alignnone size-full wp-image-6678" style="margin: 20px 0px 20px 0px;border: 1px solid #cccccc" src="https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2019/04/02/SparAppsonEMR5.png" alt="" width="757" height="452" /></p> 
<h3>Example: EMR instance template with configuration</h3> 
<p>There are different ways to set the Spark and YARN configuration parameters. One of ways is to pass these when creating the EMR cluster.</p> 
<p>To do this, in the Amazon EMR console’s <strong>Edit software settings</strong> section, you can enter the appropriately updated configuration template (<strong>Enter configuration</strong>). Or the configuration can be passed from S3 (<strong>Load JSON from S3</strong>).</p> 
<p><img class="alignnone size-full wp-image-6677" style="margin: 20px 0px 20px 0px;border: 1px solid #cccccc" src="https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2019/04/02/SparAppsonEMR6.png" alt="" width="800" height="442" /></p> 
<p>Following is a configuration template with sample values. At a minimum, calculate and set the following parameters for a successful Spark application.</p> 
<div class="hide-language"> 
 <pre><code class="lang-python">{
      &quot;InstanceGroups&quot;:[
         {
            &quot;Name&quot;:&quot;AmazonEMRMaster&quot;,
            &quot;Market&quot;:&quot;ON_DEMAND&quot;,
            &quot;InstanceRole&quot;:&quot;MASTER&quot;,
            &quot;InstanceType&quot;:&quot;r5.12xlarge&quot;,
            &quot;InstanceCount&quot;:1,
            &quot;Configurations&quot;:[
               {
                 &quot;Classification&quot;: &quot;yarn-site&quot;,
                 &quot;Properties&quot;: {
                   &quot;yarn.nodemanager.vmem-check-enabled&quot;: &quot;false&quot;,
                   &quot;yarn.nodemanager.pmem-check-enabled&quot;: &quot;false&quot;
                 }
               },
               {
                 &quot;Classification&quot;: &quot;spark&quot;,
                 &quot;Properties&quot;: {
                   &quot;maximizeResourceAllocation&quot;: &quot;false&quot;
                 }
               },
               {
                 &quot;Classification&quot;: &quot;spark-defaults&quot;,
                 &quot;Properties&quot;: {
                   &quot;spark.network.timeout&quot;: &quot;800s&quot;,
                   &quot;spark.executor.heartbeatInterval&quot;: &quot;60s&quot;,
                   &quot;spark.dynamicAllocation.enabled&quot;: &quot;false&quot;,
                   &quot;spark.driver.memory&quot;: &quot;21000M&quot;,
                   &quot;spark.executor.memory&quot;: &quot;21000M&quot;,
                   &quot;spark.executor.cores&quot;: &quot;5&quot;,
                   &quot;spark.executor.instances&quot;: &quot;171&quot;,
                   &quot;spark.yarn.executor.memoryOverhead&quot;: &quot;21000M&quot;,
                   &quot;spark.yarn.driver.memoryOverhead&quot;: &quot;21000M&quot;,
                   &quot;spark.memory.fraction&quot;: &quot;0.80&quot;,
                   &quot;spark.memory.storageFraction&quot;: &quot;0.30&quot;,
                   &quot;spark.executor.extraJavaOptions&quot;: &quot;-XX:+UseG1GC -XX:+UnlockDiagnosticVMOptions -XX:+G1SummarizeConcMark -XX:InitiatingHeapOccupancyPercent=35 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:OnOutOfMemoryError='kill -9 %p'&quot;,
                   &quot;spark.driver.extraJavaOptions&quot;: &quot;-XX:+UseG1GC -XX:+UnlockDiagnosticVMOptions -XX:+G1SummarizeConcMark -XX:InitiatingHeapOccupancyPercent=35 -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:OnOutOfMemoryError='kill -9 %p'&quot;,
                   &quot;spark.yarn.scheduler.reporterThread.maxFailures&quot;: &quot;5&quot;,
                   &quot;spark.storage.level&quot;: &quot;MEMORY_AND_DISK_SER&quot;,
                   &quot;spark.rdd.compress&quot;: &quot;true&quot;,
                   &quot;spark.shuffle.compress&quot;: &quot;true&quot;,
                   &quot;spark.shuffle.spill.compress&quot;: &quot;true&quot;,
                   &quot;spark.default.parallelism&quot;: &quot;3400&quot;
                 }
               },
               {
                 &quot;Classification&quot;: &quot;mapred-site&quot;,
                 &quot;Properties&quot;: {
                   &quot;mapreduce.map.output.compress&quot;: &quot;true&quot;
                 }
               },
               {
                 &quot;Classification&quot;: &quot;hadoop-env&quot;,
                 &quot;Configurations&quot;: [{
                   &quot;Classification&quot;: &quot;export&quot;,
                   &quot;Configurations&quot;: [],
                   &quot;Properties&quot;: {
                     &quot;JAVA_HOME&quot;: &quot;/usr/lib/jvm/java-1.8.0&quot;
                   }
                 }],
                 &quot;Properties&quot;: {}
               },
               {
                 &quot;Classification&quot;: &quot;spark-env&quot;,
                 &quot;Configurations&quot;: [{
                   &quot;Classification&quot;: &quot;export&quot;,
                   &quot;Properties&quot;: {
                     &quot;JAVA_HOME&quot;: &quot;/usr/lib/jvm/java-1.8.0&quot;
                   }
                 }],
                 &quot;Properties&quot;: {}
               }
            ]
        },
        {
            &quot;Name&quot;:&quot;AmazonEMRCore&quot;,
            &quot;Market&quot;:&quot;ON_DEMAND&quot;,
             &quot;InstanceRole&quot;:&quot;CORE&quot;,
             &quot;InstanceType&quot;:&quot;r5.12xlarge&quot;,
             &quot;InstanceCount&quot;:19,
             &quot;Configurations&quot;:[        
        ..............
        ..............
        ..............
        }
      ],
      &quot;Ec2KeyName&quot;:&quot;KEY_NAME&quot;
  } </code></pre> 
</div> 
<h2>Conclusion</h2> 
<p>In this blog post, I detailed the possible out-of-memory errors, their causes, and a list of best practices to prevent these errors when submitting a Spark application on Amazon EMR.</p> 
<p>My colleagues and I formed these best practices after thorough research and understanding of various Spark configuration properties and testing multiple Spark applications. These best practices apply to most of out-of-memory scenarios, though there might be some rare scenarios where they don’t apply. However, we believe that this blog post provides all the details needed so you can tweak parameters and successfully run a Spark application.</p> 
<p>&nbsp;</p> 
<hr /> 
<h3>About the Author</h3> 
<p><img class="size-full wp-image-6691 alignleft" src="https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2019/04/03/karushan.png" alt="" width="113" height="149" /><strong>Karunanithi Shanmugam is a data engineer with AWS Tech and Finance</strong>.</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p> 
<p>&nbsp;</p>